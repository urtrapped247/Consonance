{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "from music21 import stream, note, duration, pitch\n",
    "from music21.musicxml import m21ToXml\n",
    "\n",
    "# Suppress annoying MusicXMLWarning\n",
    "warnings.filterwarnings(\"ignore\", category=m21ToXml.MusicXMLWarning)\n",
    "\n",
    "def generate_random_note():\n",
    "    '''\n",
    "    A function to generate a random note based on a predefined list\n",
    "    of pitches and durations.\n",
    "    '''\n",
    "    pitches = ['C4', 'D4', 'E4', 'F4', 'G4', 'A4', 'B4', 'C5', 'D5', 'E5', 'F5', 'G5']\n",
    "    durations = ['whole', 'half', 'quarter', 'eighth', '16th']\n",
    "\n",
    "    selected_pitch = random.choice(pitches)\n",
    "    selected_duration = random.choice(durations)\n",
    "\n",
    "    n = note.Note()\n",
    "    n.pitch = pitch.Pitch(selected_pitch)\n",
    "    n.duration = duration.Duration(selected_duration)\n",
    "\n",
    "    return n, selected_pitch, selected_duration\n",
    "\n",
    "def pitch_to_label(pitch):\n",
    "    pitch_dict = {'C4': -6, 'D4': -5, 'E4': -4, 'F4': -3, 'G4': -2, 'A4': -1, 'B4': 0,\n",
    "                  'C5': 1, 'D5': 2, 'E5': 3, 'F5': 4, 'G5': 5}\n",
    "    return pitch_dict[pitch]\n",
    "\n",
    "def generate_synthetic_single_musicxml(num_samples=10, output_folder='../raw_data/musicxml_files', label_file='../raw_data/labels.csv'):\n",
    "    '''\n",
    "    A function to create musicXML files with a single note of music, along with a label file.\n",
    "    '''\n",
    "    # get CWD and create folders if needed\n",
    "    current_dir = os.getcwd()\n",
    "    output_folder = os.path.abspath(os.path.join(current_dir, output_folder))\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    label_file = os.path.abspath(os.path.join(current_dir, label_file))\n",
    "\n",
    "    # create music files and labels\n",
    "    with open(label_file, 'w', newline='') as csvfile:\n",
    "        label_writer = csv.writer(csvfile)\n",
    "        label_writer.writerow(['filename', 'label'])\n",
    "        for i in range(num_samples):\n",
    "            s = stream.Stream()\n",
    "            n, selected_pitch, selected_duration = generate_random_note()\n",
    "            s.append(n)\n",
    "            filename = f'note_{selected_pitch}_{selected_duration}_{i}.musicxml'\n",
    "            s.write('musicxml', fp=os.path.join(output_folder, filename))\n",
    "            label = pitch_to_label(selected_pitch)\n",
    "            label_writer.writerow([filename.replace('.musicxml', '.png'), label])\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_synthetic_single_musicxml(num_samples=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PNG Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import platform\n",
    "import os\n",
    "\n",
    "\n",
    "# get the right path for musescore based on system\n",
    "def get_musescore_path():\n",
    "    system = platform.system()\n",
    "    if system == 'Windows':\n",
    "        return r'C:\\Program Files\\MuseScore 4\\bin\\MuseScore4.exe'  # Update this path if necessary\n",
    "    elif system == 'Darwin':  # macOS\n",
    "        return '/Applications/MuseScore 4.app/Contents/MacOS/mscore'\n",
    "    elif system == 'Linux':\n",
    "        return '/usr/bin/musescore4'  # Update this path if necessary\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported operating system\")\n",
    "\n",
    "\n",
    "def convert_musicxml_to_png(input_folder='../raw_data/musicxml_files', output_folder='../raw_data/sheet_images'):\n",
    "    current_dir = os.getcwd()\n",
    "    input_folder = os.path.abspath(os.path.join(current_dir, input_folder))\n",
    "    output_folder = os.path.abspath(os.path.join(current_dir, output_folder))\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    musescore_path = get_musescore_path()\n",
    "\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        if file_name.endswith('.musicxml'):\n",
    "            input_path = os.path.join(input_folder, file_name)\n",
    "            output_filename = file_name.replace('.musicxml', '.png')\n",
    "            output_path = os.path.join(output_folder, output_filename)\n",
    "            result = subprocess.run([musescore_path, input_path, '-o', output_path], stderr=subprocess.PIPE)\n",
    "            if result.returncode != 0:\n",
    "                print(f\"Error processing {file_name}: {result.stderr.decode('utf-8')}\")\n",
    "\n",
    "            # Check if the file has a '-1' suffix and rename it\n",
    "            generated_filename = output_filename.replace('.png', '-1.png')\n",
    "            generated_path = os.path.join(output_folder, generated_filename)\n",
    "            if os.path.exists(generated_path):\n",
    "                os.rename(generated_path, output_path)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_musicxml_to_png()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Image and Embed Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For rows of music, to be tried later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#### This will need to be adjusted (img --> file) #####\n",
    "\n",
    "def create_dataset(num_samples):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for i in range(num_samples):\n",
    "        img = cv2.imread(f'random_sample_{i}.png', cv2.IMREAD_GRAYSCALE)\n",
    "        img_array = np.array(img)\n",
    "\n",
    "        # Example bounding box creation (this should be based on actual note positions)\n",
    "        bounding_boxes = [(50, 50, 100, 100)]  # Placeholder\n",
    "        label = ['C4']  # Placeholder\n",
    "\n",
    "        images.append(img_array)\n",
    "        labels.append((bounding_boxes, label))\n",
    "\n",
    "    return np.array(images), labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For single note files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Travis Code for Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def crop_note_from_png_folder(input_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Crops all PNG images in the specified folder to the specified dimensions.\n",
    "\n",
    "    Parameters:\n",
    "    - input_folder (str): The path to the input folder containing PNG images.\n",
    "    - output_folder (str): The path to the folder to save the cropped images.\n",
    "    \"\"\"\n",
    "    # Define the crop box (left, upper, right, lower)\n",
    "    crop_box = (506, 536, 580, 870)  # Replace these values with your desired dimensions\n",
    "\n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Iterate through all files in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.lower().endswith('.png'):\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "            output_path = os.path.join(output_folder, filename)\n",
    "\n",
    "            # Open the image file\n",
    "            with Image.open(input_path) as img:\n",
    "                # Crop the image using the provided crop box\n",
    "                cropped_img = img.crop(crop_box)\n",
    "\n",
    "                # Save the cropped image\n",
    "                cropped_img.save(output_path)\n",
    "\n",
    "            # print(f'Cropped image saved to {output_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = '../raw_data/sheet_images'\n",
    "output_folder = '../raw_data/cropped_images'\n",
    "crop_note_from_png_folder(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### for if we dont have a labeled filed ########\n",
    "\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# def process_single_note_image(image_path, label):\n",
    "#     img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "#     img_array = np.array(img)\n",
    "\n",
    "#     # As we know it's a single note, let's assume the bounding box covers most of the image\n",
    "#     h, w = img_array.shape\n",
    "#     bounding_box = [0, 0, w, h]\n",
    "\n",
    "#     return img_array, bounding_box, label\n",
    "\n",
    "# def create_single_note_dataset(image_folder='../raw_data/sheet_images', label_data='../raw_data/musicxml_files'):\n",
    "#     images = []\n",
    "#     bounding_boxes = []\n",
    "#     labels = []\n",
    "\n",
    "#     for file_name in os.listdir(image_folder):\n",
    "#         if file_name.endswith('.png'):\n",
    "#             note_info = file_name.replace('.png', '').split('_')[1:]  # Extract pitch and duration from filename\n",
    "#             label = '_'.join(note_info)\n",
    "\n",
    "#             img_array, bounding_box, label = process_single_note_image(os.path.join(image_folder, file_name), label)\n",
    "#             images.append(img_array)\n",
    "#             bounding_boxes.append(bounding_box)\n",
    "#             labels.append(label)\n",
    "\n",
    "#     return np.array(images), bounding_boxes, labels\n",
    "\n",
    "\n",
    "\n",
    "##### using csv file for labels #########\n",
    "\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def load_labels(label_file='../raw_data/labels.csv'):\n",
    "    labels_df = pd.read_csv(label_file)\n",
    "    return labels_df.set_index('filename').to_dict()['label']\n",
    "\n",
    "def create_single_note_dataset(image_folder='../raw_data/cropped_images', label_file='../raw_data/labels.csv'):\n",
    "    labels = load_labels(label_file)\n",
    "    images = []\n",
    "    bounding_boxes = []\n",
    "    image_labels = []\n",
    "\n",
    "    for file_name in os.listdir(image_folder):\n",
    "        if file_name.endswith('.png'):\n",
    "            img_path = os.path.join(image_folder, file_name)\n",
    "            label = labels[file_name]\n",
    "            img_array = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            # Create a bounding box covering the entire image\n",
    "            h, w = img_array.shape\n",
    "            bounding_box = [0, 0, w, h]\n",
    "\n",
    "            images.append(img_array)\n",
    "            bounding_boxes.append(bounding_box)\n",
    "            image_labels.append(label)\n",
    "\n",
    "    return np.array(images), bounding_boxes, image_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, bounding_boxes, image_labels = create_single_note_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 334, 74)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of resized images: (500, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Example target size for the model (for CNNs, it could be something like 64x64 or 128x128)\n",
    "target_size = (128, 128)  # Width x Height\n",
    "\n",
    "# Assuming `images` is a list of images loaded as numpy arrays\n",
    "resized_images = []\n",
    "\n",
    "for img in images:\n",
    "    resized_img = cv2.resize(img, target_size, interpolation=cv2.INTER_AREA)\n",
    "    resized_images.append(resized_img)\n",
    "\n",
    "# Convert back to numpy array\n",
    "resized_images = np.array(resized_images)\n",
    "\n",
    "# Check the shape of the resized images\n",
    "print(f\"Shape of resized images: {resized_images.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_with_aspect_ratio(img, target_size):\n",
    "    h, w = img.shape\n",
    "\n",
    "    # Calculate the aspect ratio\n",
    "    aspect_ratio = w / h\n",
    "\n",
    "    # Determine the target width and height based on the target size\n",
    "    if aspect_ratio > 1:  # Wider image\n",
    "        new_w = target_size[0]\n",
    "        new_h = int(target_size[0] / aspect_ratio)\n",
    "    else:  # Taller image\n",
    "        new_h = target_size[1]\n",
    "        new_w = int(target_size[1] * aspect_ratio)\n",
    "\n",
    "    # Resize the image\n",
    "    resized_img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # Add padding to make the image square\n",
    "    delta_w = target_size[0] - new_w\n",
    "    delta_h = target_size[1] - new_h\n",
    "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
    "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
    "\n",
    "    color = [255]  # Assuming a white background (255 for grayscale)\n",
    "    padded_img = cv2.copyMakeBorder(resized_img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
    "\n",
    "    return padded_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of resized and padded images: (500, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "resized_images = [resize_with_aspect_ratio(img, target_size) for img in images]\n",
    "resized_images = np.array(resized_images)\n",
    "\n",
    "print(f\"Shape of resized and padded images: {resized_images.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_logistic_regression(X, y):\n",
    "    X_flat = X.reshape(X.shape[0], -1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_flat, y, test_size=0.2)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, models\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_cnn(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    model = create_cnn_model(X_train.shape[1:], num_classes=10)  # Example with 10 classes\n",
    "    model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "    return model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for running the model, don't run this cell until others are good\n",
    "\n",
    "images, labels = create_dataset(100)  # Generate 100 samples\n",
    "preprocessed_images = np.array([preprocess_image(img) for img in images])\n",
    "\n",
    "# Logistic Regression\n",
    "logistic_accuracy = train_logistic_regression(preprocessed_images, labels)\n",
    "\n",
    "# CNN\n",
    "# cnn_accuracy = train_cnn(preprocessed_images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assume 'images' is your X and 'image_labels' is your y from step 4\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, image_labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Flatten the images for logistic regression\n",
    "n_samples, h, w = X_train.shape\n",
    "X_train_flat = X_train.reshape(n_samples, h * w)\n",
    "X_test_flat = X_test.reshape(X_test.shape[0], h * w)\n",
    "\n",
    "# Train the logistic regression model\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "logistic_model.fit(X_train_flat, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred = logistic_model.predict(X_test_flat)\n",
    "logistic_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Logistic Regression Accuracy: {logistic_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing/Troubleshooting...Not Needed in Python file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check shape of the images array\n",
    "print(f\"Shape of images array before reshaping: {images.shape}\")\n",
    "\n",
    "# Ensure images are correctly shaped for CNN\n",
    "if len(images.shape) == 3:  # Correct shape should be (num_images, height, width)\n",
    "    X_cnn = np.array(images).reshape(-1, images.shape[1], images.shape[2], 1)\n",
    "else:\n",
    "    raise ValueError(\"Images array is not in the expected shape. Check the preprocessing steps.\")\n",
    "\n",
    "# Proceed with splitting and training as described earlier\n",
    "X_train_cnn, X_test_cnn, y_train_cnn, y_test_cnn = train_test_split(X_cnn, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_single_note_dataset(image_folder='../raw_data/sheet_images', label_file='../raw_data/labels.csv'):\n",
    "    labels = load_labels(label_file)\n",
    "    images = []\n",
    "    bounding_boxes = []\n",
    "    image_labels = []\n",
    "\n",
    "    for file_name in os.listdir(image_folder):\n",
    "        if file_name.endswith('.png'):\n",
    "            img_path = os.path.join(image_folder, file_name)\n",
    "            label = labels[file_name]\n",
    "\n",
    "            # Load image and check shape\n",
    "            img_array = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            print(f\"Loaded {file_name} with shape {img_array.shape}\")\n",
    "\n",
    "            # Verify that the image is loaded correctly as a 2D array\n",
    "            if len(img_array.shape) != 2:\n",
    "                raise ValueError(f\"Image {file_name} is not in the expected shape (height, width).\")\n",
    "\n",
    "            # Create a bounding box covering the entire image\n",
    "            h, w = img_array.shape\n",
    "            bounding_box = [0, 0, w, h]\n",
    "\n",
    "            images.append(img_array)\n",
    "            bounding_boxes.append(bounding_box)\n",
    "            image_labels.append(label)\n",
    "\n",
    "    return np.array(images), bounding_boxes, image_labels\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Consonance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
