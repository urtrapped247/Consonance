{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import stream, note, duration, pitch, metadata, clef\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "from music21.musicxml import m21ToXml\n",
    "\n",
    "# Suppress annoying MusicXMLWarning\n",
    "warnings.filterwarnings(\"ignore\", category=m21ToXml.MusicXMLWarning)\n",
    "\n",
    "\n",
    "def generate_random_note():\n",
    "    '''\n",
    "    A function to generate a random note based on a predefined list\n",
    "    of pitches and durations.\n",
    "    '''\n",
    "\n",
    "    # Define a list of possible pitches and durations\n",
    "    pitches = ['C4', 'D4', 'E4', 'F4', 'G4', 'A4', 'B4', 'C5', 'D5', 'E5', 'F5', 'G5']\n",
    "    durations = ['whole', 'half', 'quarter', 'eighth', '16th']\n",
    "\n",
    "    # Select a random pitch and duration\n",
    "    selected_pitch = random.choice(pitches)\n",
    "    selected_duration = random.choice(durations)\n",
    "\n",
    "    # Create and return a music21 note\n",
    "    n = note.Note()\n",
    "    n.pitch = pitch.Pitch(selected_pitch)\n",
    "    n.duration = duration.Duration(selected_duration)\n",
    "    return n, selected_pitch, selected_duration\n",
    "\n",
    "def generate_synthetic_single_musicxml(num_samples=10, output_folder='../raw_data/musicxml_files'):\n",
    "    '''\n",
    "    A function to create a folder of MusicXML files.\n",
    "    '''\n",
    "    # check for output - Use this for .py\n",
    "    # output_folder = os.path.join(os.path.dirname(__file__), os.pardir, 'musicxml_files')\n",
    "    # if not os.path.exists(output_folder):\n",
    "    #     os.makedirs(output_folder)\n",
    "\n",
    "    # for our notebook since __file__ seems to not work\n",
    "    current_dir = os.getcwd()\n",
    "    output_folder = os.path.abspath(os.path.join(current_dir, output_folder))\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    synthetic_data = []\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        \"\"\"\n",
    "        to generate a file with a single note\n",
    "        \"\"\"\n",
    "        s = stream.Stream()\n",
    "        n, selected_pitch, selected_duration = generate_random_note()\n",
    "        s.append(n)\n",
    "        filename = f'{output_folder}/note_{selected_pitch}_{selected_duration}.musicxml'\n",
    "        s.write('musicxml', fp=filename)\n",
    "\n",
    "        synthetic_data.append(s)\n",
    "\n",
    "    return synthetic_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PNG Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import platform\n",
    "import os\n",
    "\n",
    "\n",
    "# get the right path for musescore based on system\n",
    "def get_musescore_path():\n",
    "    system = platform.system()\n",
    "    if system == 'Windows':\n",
    "        return r'C:\\Program Files\\MuseScore 4\\bin\\MuseScore4.exe'  # Update this path if necessary\n",
    "    elif system == 'Darwin':  # macOS\n",
    "        return '/Applications/MuseScore 4.app/Contents/MacOS/mscore'\n",
    "    elif system == 'Linux':\n",
    "        return '/usr/bin/musescore4'  # Update this path if necessary\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported operating system\")\n",
    "\n",
    "\n",
    "def convert_musicxml_to_png(input_folder='../raw_data/musicxml_files', output_folder='../raw_data/sheet_images'):\n",
    "    current_dir = os.getcwd()\n",
    "    input_folder = os.path.abspath(os.path.join(current_dir, input_folder))\n",
    "    output_folder = os.path.abspath(os.path.join(current_dir, output_folder))\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    musescore_path = get_musescore_path()\n",
    "\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        if file_name.endswith('.musicxml'):\n",
    "            input_path = os.path.join(input_folder, file_name)\n",
    "            output_filename = file_name.replace('.musicxml', '.png')\n",
    "            output_path = os.path.join(output_folder, output_filename)\n",
    "            result = subprocess.run([musescore_path, input_path, '-o', output_path], stderr=subprocess.PIPE)\n",
    "            if result.returncode != 0:\n",
    "                print(f\"Error processing {file_name}: {result.stderr.decode('utf-8')}\")\n",
    "\n",
    "            # Check if the file has a '-1' suffix and rename it\n",
    "            generated_filename = output_filename.replace('.png', '-1.png')\n",
    "            generated_path = os.path.join(output_folder, generated_filename)\n",
    "            if os.path.exists(generated_path):\n",
    "                os.rename(generated_path, output_path)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Image and Embed Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For rows of music, to be tried later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#### This will need to be adjusted (img --> file) #####\n",
    "\n",
    "def create_dataset(num_samples):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for i in range(num_samples):\n",
    "        img = cv2.imread(f'random_sample_{i}.png', cv2.IMREAD_GRAYSCALE)\n",
    "        img_array = np.array(img)\n",
    "\n",
    "        # Example bounding box creation (this should be based on actual note positions)\n",
    "        bounding_boxes = [(50, 50, 100, 100)]  # Placeholder\n",
    "        label = ['C4']  # Placeholder\n",
    "\n",
    "        images.append(img_array)\n",
    "        labels.append((bounding_boxes, label))\n",
    "\n",
    "    return np.array(images), labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For single note files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def process_single_note_image(image_path, label):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img_array = np.array(img)\n",
    "\n",
    "    # As we know it's a single note, let's assume the bounding box covers most of the image\n",
    "    h, w = img_array.shape\n",
    "    bounding_box = [0, 0, w, h]\n",
    "\n",
    "    return img_array, bounding_box, label\n",
    "\n",
    "def create_single_note_dataset(image_folder='../raw_data/sheet_images', label_data='../raw_data/musicxml_files'):\n",
    "    images = []\n",
    "    bounding_boxes = []\n",
    "    labels = []\n",
    "\n",
    "    for file_name in os.listdir(image_folder):\n",
    "        if file_name.endswith('.png'):\n",
    "            note_info = file_name.replace('.png', '').split('_')[1:]  # Extract pitch and duration from filename\n",
    "            label = '_'.join(note_info)\n",
    "\n",
    "            img_array, bounding_box, label = process_single_note_image(os.path.join(image_folder, file_name), label)\n",
    "            images.append(img_array)\n",
    "            bounding_boxes.append(bounding_box)\n",
    "            labels.append(label)\n",
    "\n",
    "    return np.array(images), bounding_boxes, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grayscale, thresholding, resizing for model\n",
    "\n",
    "def preprocess_image(image):\n",
    "    _, thresh_image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "    resized_image = cv2.resize(thresh_image, (128, 128))\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_logistic_regression(X, y):\n",
    "    X_flat = X.reshape(X.shape[0], -1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_flat, y, test_size=0.2)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, models\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_cnn(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    model = create_cnn_model(X_train.shape[1:], num_classes=10)  # Example with 10 classes\n",
    "    model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "    return model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for running the model, don't run this cell until others are good\n",
    "\n",
    "images, labels = create_dataset(100)  # Generate 100 samples\n",
    "preprocessed_images = np.array([preprocess_image(img) for img in images])\n",
    "\n",
    "# Logistic Regression\n",
    "logistic_accuracy = train_logistic_regression(preprocessed_images, labels)\n",
    "\n",
    "# CNN\n",
    "cnn_accuracy = train_cnn(preprocessed_images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Consonance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
