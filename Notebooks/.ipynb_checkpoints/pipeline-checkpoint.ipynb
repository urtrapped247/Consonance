{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "from music21 import stream, note, duration, pitch\n",
    "from music21.musicxml import m21ToXml\n",
    "\n",
    "# Suppress annoying MusicXMLWarning\n",
    "warnings.filterwarnings(\"ignore\", category=m21ToXml.MusicXMLWarning)\n",
    "\n",
    "def generate_random_note():\n",
    "    '''\n",
    "    A function to generate a random note based on a predefined list\n",
    "    of pitches and durations.\n",
    "    '''\n",
    "    pitches = ['C4', 'D4', 'E4', 'F4', 'G4', 'A4', 'B4', 'C5', 'D5', 'E5', 'F5', 'G5']\n",
    "    durations = ['whole', 'half', 'quarter', 'eighth', '16th']\n",
    "\n",
    "    selected_pitch = random.choice(pitches)\n",
    "    selected_duration = random.choice(durations)\n",
    "\n",
    "    n = note.Note()\n",
    "    n.pitch = pitch.Pitch(selected_pitch)\n",
    "    n.duration = duration.Duration(selected_duration)\n",
    "\n",
    "    return n, selected_pitch, selected_duration\n",
    "\n",
    "def pitch_to_label(pitch):\n",
    "    pitch_dict = {'C4': -6, 'D4': -5, 'E4': -4, 'F4': -3, 'G4': -2, 'A4': -1, 'B4': 0,\n",
    "                  'C5': 1, 'D5': 2, 'E5': 3, 'F5': 4, 'G5': 5}\n",
    "    return pitch_dict[pitch]\n",
    "\n",
    "def generate_synthetic_single_musicxml(num_samples=10, output_folder='../raw_data/musicxml_files', label_file='../raw_data/labels.csv'):\n",
    "    '''\n",
    "    A function to create musicXML files with a single note of music, along with a label file.\n",
    "    '''\n",
    "    # get CWD and create folders if needed\n",
    "    current_dir = os.getcwd()\n",
    "    output_folder = os.path.abspath(os.path.join(current_dir, output_folder))\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    label_file = os.path.abspath(os.path.join(current_dir, label_file))\n",
    "\n",
    "    # create music files and labels\n",
    "    with open(label_file, 'w', newline='') as csvfile:\n",
    "        label_writer = csv.writer(csvfile)\n",
    "        label_writer.writerow(['filename', 'label'])\n",
    "        for i in range(num_samples):\n",
    "            s = stream.Stream()\n",
    "            n, selected_pitch, selected_duration = generate_random_note()\n",
    "            s.append(n)\n",
    "            filename = f'note_{selected_pitch}_{selected_duration}_{i}.musicxml'\n",
    "            s.write('musicxml', fp=os.path.join(output_folder, filename))\n",
    "            label = pitch_to_label(selected_pitch)\n",
    "            label_writer.writerow([filename.replace('.musicxml', '.png'), label])\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_synthetic_single_musicxml()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PNG Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import platform\n",
    "import os\n",
    "\n",
    "\n",
    "# get the right path for musescore based on system\n",
    "def get_musescore_path():\n",
    "    system = platform.system()\n",
    "    if system == 'Windows':\n",
    "        return r'C:\\Program Files\\MuseScore 4\\bin\\MuseScore4.exe'  # Update this path if necessary\n",
    "    elif system == 'Darwin':  # macOS\n",
    "        return '/Applications/MuseScore 4.app/Contents/MacOS/mscore'\n",
    "    elif system == 'Linux':\n",
    "        return '/usr/bin/musescore4'  # Update this path if necessary\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported operating system\")\n",
    "\n",
    "\n",
    "def convert_musicxml_to_png(input_folder='../raw_data/musicxml_files', output_folder='../raw_data/sheet_images'):\n",
    "    current_dir = os.getcwd()\n",
    "    input_folder = os.path.abspath(os.path.join(current_dir, input_folder))\n",
    "    output_folder = os.path.abspath(os.path.join(current_dir, output_folder))\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    musescore_path = get_musescore_path()\n",
    "\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        if file_name.endswith('.musicxml'):\n",
    "            input_path = os.path.join(input_folder, file_name)\n",
    "            output_filename = file_name.replace('.musicxml', '.png')\n",
    "            output_path = os.path.join(output_folder, output_filename)\n",
    "            result = subprocess.run([musescore_path, input_path, '-o', output_path], stderr=subprocess.PIPE)\n",
    "            if result.returncode != 0:\n",
    "                print(f\"Error processing {file_name}: {result.stderr.decode('utf-8')}\")\n",
    "\n",
    "            # Check if the file has a '-1' suffix and rename it\n",
    "            generated_filename = output_filename.replace('.png', '-1.png')\n",
    "            generated_path = os.path.join(output_folder, generated_filename)\n",
    "            if os.path.exists(generated_path):\n",
    "                os.rename(generated_path, output_path)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_musicxml_to_png()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Image and Embed Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For rows of music, to be tried later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#### This will need to be adjusted (img --> file) #####\n",
    "\n",
    "def create_dataset(num_samples):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for i in range(num_samples):\n",
    "        img = cv2.imread(f'random_sample_{i}.png', cv2.IMREAD_GRAYSCALE)\n",
    "        img_array = np.array(img)\n",
    "\n",
    "        # Example bounding box creation (this should be based on actual note positions)\n",
    "        bounding_boxes = [(50, 50, 100, 100)]  # Placeholder\n",
    "        label = ['C4']  # Placeholder\n",
    "\n",
    "        images.append(img_array)\n",
    "        labels.append((bounding_boxes, label))\n",
    "\n",
    "    return np.array(images), labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For single note files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### for if we dont have a labeled filed ########\n",
    "\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# def process_single_note_image(image_path, label):\n",
    "#     img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "#     img_array = np.array(img)\n",
    "\n",
    "#     # As we know it's a single note, let's assume the bounding box covers most of the image\n",
    "#     h, w = img_array.shape\n",
    "#     bounding_box = [0, 0, w, h]\n",
    "\n",
    "#     return img_array, bounding_box, label\n",
    "\n",
    "# def create_single_note_dataset(image_folder='../raw_data/sheet_images', label_data='../raw_data/musicxml_files'):\n",
    "#     images = []\n",
    "#     bounding_boxes = []\n",
    "#     labels = []\n",
    "\n",
    "#     for file_name in os.listdir(image_folder):\n",
    "#         if file_name.endswith('.png'):\n",
    "#             note_info = file_name.replace('.png', '').split('_')[1:]  # Extract pitch and duration from filename\n",
    "#             label = '_'.join(note_info)\n",
    "\n",
    "#             img_array, bounding_box, label = process_single_note_image(os.path.join(image_folder, file_name), label)\n",
    "#             images.append(img_array)\n",
    "#             bounding_boxes.append(bounding_box)\n",
    "#             labels.append(label)\n",
    "\n",
    "#     return np.array(images), bounding_boxes, labels\n",
    "\n",
    "\n",
    "\n",
    "##### using csv file for labels #########\n",
    "\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def load_labels(label_file='../raw_data/labels.csv'):\n",
    "    labels_df = pd.read_csv(label_file)\n",
    "    return labels_df.set_index('filename').to_dict()['label']\n",
    "\n",
    "def create_single_note_dataset(image_folder='../raw_data/sheet_images', label_file='../raw_data/labels.csv'):\n",
    "    labels = load_labels(label_file)\n",
    "    images = []\n",
    "    bounding_boxes = []\n",
    "    image_labels = []\n",
    "\n",
    "    for file_name in os.listdir(image_folder):\n",
    "        if file_name.endswith('.png'):\n",
    "            img_path = os.path.join(image_folder, file_name)\n",
    "            label = labels[file_name]\n",
    "            img_array = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            # Create a bounding box covering the entire image\n",
    "            h, w = img_array.shape\n",
    "            bounding_box = [0, 0, w, h]\n",
    "\n",
    "            images.append(img_array)\n",
    "            bounding_boxes.append(bounding_box)\n",
    "            image_labels.append(label)\n",
    "\n",
    "    return np.array(images), bounding_boxes, image_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = create_single_note_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grayscale, thresholding, resizing for model\n",
    "\n",
    "def preprocess_image(image):\n",
    "    _, thresh_image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "    resized_image = cv2.resize(thresh_image, (128, 128))\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_logistic_regression(X, y):\n",
    "    X_flat = X.reshape(X.shape[0], -1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_flat, y, test_size=0.2)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, models\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_cnn(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    model = create_cnn_model(X_train.shape[1:], num_classes=10)  # Example with 10 classes\n",
    "    model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "    return model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for running the model, don't run this cell until others are good\n",
    "\n",
    "images, labels = create_dataset(100)  # Generate 100 samples\n",
    "preprocessed_images = np.array([preprocess_image(img) for img in images])\n",
    "\n",
    "# Logistic Regression\n",
    "logistic_accuracy = train_logistic_regression(preprocessed_images, labels)\n",
    "\n",
    "# CNN\n",
    "cnn_accuracy = train_cnn(preprocessed_images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Assume 'images' is your X and 'image_labels' is your y from step 4\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(images, \u001b[43mimage_labels\u001b[49m, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_labels' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assume 'images' is your X and 'image_labels' is your y from step 4\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, image_labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Flatten the images for logistic regression\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m n_samples, h, w \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m      6\u001b[0m X_train_flat \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mreshape(n_samples, h \u001b[38;5;241m*\u001b[39m w)\n\u001b[1;32m      7\u001b[0m X_test_flat \u001b[38;5;241m=\u001b[39m X_test\u001b[38;5;241m.\u001b[39mreshape(X_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], h \u001b[38;5;241m*\u001b[39m w)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Flatten the images for logistic regression\n",
    "n_samples, h, w = X_train.shape\n",
    "X_train_flat = X_train.reshape(n_samples, h * w)\n",
    "X_test_flat = X_test.reshape(X_test.shape[0], h * w)\n",
    "\n",
    "# Train the logistic regression model\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "logistic_model.fit(X_train_flat, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred = logistic_model.predict(X_test_flat)\n",
    "logistic_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Logistic Regression Accuracy: {logistic_accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Consonance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
